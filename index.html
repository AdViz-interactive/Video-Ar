<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>AdViz Smart AR</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            background-color: #111;
            color: white;
            /* CRITICAL: Disables native browser zoom/scroll so our pinch works */
            touch-action: none; 
            user-select: none;
            -webkit-user-select: none;
        }

        #overlay {
            position: absolute;
            top: 0; left: 0; width: 100%; height: 100%;
            pointer-events: none;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            z-index: 100;
        }

        #setup-panel {
            pointer-events: auto;
            background: rgba(20, 20, 20, 0.95);
            padding: 24px;
            border-radius: 16px;
            text-align: center;
            border: 1px solid rgba(255, 255, 255, 0.1);
            max-width: 85%;
            box-shadow: 0 10px 40px rgba(0,0,0,0.6);
            transition: opacity 0.3s;
        }

        h1 { margin: 0 0 10px 0; font-size: 1.4rem; }
        p { color: #aaa; margin-bottom: 20px; font-size: 0.9rem; line-height: 1.4; }

        .btn-primary {
            background-color: #4f46e5;
            color: white;
            padding: 12px 24px;
            border-radius: 8px;
            font-weight: 600;
            border: none;
            cursor: pointer;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            font-size: 1rem;
            transition: background 0.2s;
        }

        .file-wrapper {
            position: relative;
            display: inline-block;
            overflow: hidden;
            margin-bottom: 15px;
        }
        .file-wrapper input[type=file] {
            font-size: 100px;
            position: absolute;
            left: 0; top: 0; opacity: 0;
            cursor: pointer;
            width: 100%; height: 100%;
        }

        #status-msg { margin-top: 15px; font-size: 0.9rem; color: #888; min-height: 20px; }
        .success { color: #4ade80 !important; font-weight: bold; }
        
        #ar-btn-container {
            margin-top: 20px;
            height: 50px;
            display: flex;
            justify-content: center;
            pointer-events: auto;
        }

        button#ARButton {
            position: static !important;
            padding: 12px 30px !important;
            font-size: 16px !important;
            border-radius: 8px !important;
            background-color: #22c55e !important;
            color: white !important;
            width: auto !important;
        }

        #feedback {
            position: absolute;
            top: 15%;
            background: rgba(0,0,0,0.7);
            padding: 10px 20px;
            border-radius: 30px;
            font-size: 14px;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.3s;
            z-index: 102;
        }
        #feedback.visible { opacity: 1; }

        /* Debug for Pinch if needed */
        #debug {
            position: absolute;
            bottom: 10px; left: 10px;
            font-size: 10px; color: #555;
            pointer-events: none;
        }
    </style>
</head>
<body>

    <div id="overlay">
        <div id="setup-panel">
            <h1>AdViz Smart AR</h1>
            <p>1. Upload Video<br>2. Wait for Green Button<br>3. Scan Wall or Floor</p>
            
            <div class="file-wrapper">
                <button class="btn-primary"><span>üìÅ Choose Video</span></button>
                <input type="file" id="video-input" accept="video/*">
            </div>

            <div id="status-msg">Waiting for video...</div>
            <div id="ar-btn-container"></div>
        </div>
        
        <div id="feedback">Scanning surface...</div>
        <div id="debug"></div>
    </div>

    <!-- Video Loop enabled -->
    <video id="video-source" loop muted playsinline webkit-playsinline crossorigin="anonymous" style="display:none"></video>

    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { ARButton } from 'three/addons/webxr/ARButton.js';

        let container, camera, scene, renderer;
        let controller, reticle;
        let hitTestSource = null;
        let hitTestSourceRequested = false;
        let videoElement, videoTexture, videoMesh;
        let isVideoPlaced = false;
        let videoAspect = 1.77;
        let videoHeight = 1.0; 

        // Gestures
        let touchStartDistance = 0;
        let startScale = new THREE.Vector3();
        let isPinching = false;

        const setupPanel = document.getElementById('setup-panel');
        const feedbackEl = document.getElementById('feedback');
        const statusMsg = document.getElementById('status-msg');
        const arContainer = document.getElementById('ar-btn-container');

        // Raycaster
        const raycaster = new THREE.Raycaster();
        const tempMatrix = new THREE.Matrix4();

        init();
        animate();

        function init() {
            container = document.createElement('div');
            document.body.appendChild(container);

            scene = new THREE.Scene();
            scene.background = null; 

            camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.01, 20);

            const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 3);
            light.position.set(0.5, 1, 0.25);
            scene.add(light);

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setPixelRatio(1); // Keep 1 for mobile performance
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.xr.enabled = true;
            container.appendChild(renderer.domElement);

            setupVideoInput();

            // Reticle: Visual guide
            reticle = new THREE.Mesh(
                new THREE.RingGeometry(0.15, 0.2, 32).rotateX(-Math.PI / 2),
                new THREE.MeshBasicMaterial({ color: 0xffffff })
            );
            reticle.matrixAutoUpdate = false;
            reticle.visible = false;
            scene.add(reticle);

            controller = renderer.xr.getController(0);
            controller.addEventListener('select', onSelect);
            scene.add(controller);

            window.addEventListener('resize', onWindowResize);
            
            // ROBUST PINCH LISTENERS
            // Attached to canvas to ensure we capture the AR interactions
            renderer.domElement.addEventListener('touchstart', onTouchStart, { passive: false });
            renderer.domElement.addEventListener('touchmove', onTouchMove, { passive: false });
            renderer.domElement.addEventListener('touchend', onTouchEnd);
        }

        function setupVideoInput() {
            videoElement = document.getElementById('video-source');
            const input = document.getElementById('video-input');

            input.addEventListener('change', (e) => {
                const file = e.target.files[0];
                if (!file) return;

                statusMsg.textContent = "Loading...";
                statusMsg.className = "";
                videoElement.src = URL.createObjectURL(file);

                videoElement.onloadedmetadata = () => {
                    statusMsg.textContent = "Ready! Tap START AR below.";
                    statusMsg.className = "success";
                    videoAspect = videoElement.videoWidth / videoElement.videoHeight;

                    arContainer.innerHTML = '';

                    const button = ARButton.createButton(renderer, {
                        requiredFeatures: ['hit-test'],
                        optionalFeatures: ['dom-overlay'],
                        domOverlay: { root: document.getElementById('overlay') }
                    });
                    
                    button.addEventListener('click', () => {
                        setupPanel.style.display = 'none';
                        createVideoMesh();
                    });

                    arContainer.appendChild(button);
                };
            });
        }

        function createVideoMesh() {
            videoTexture = new THREE.VideoTexture(videoElement);
            videoTexture.colorSpace = THREE.SRGBColorSpace;
            videoTexture.minFilter = THREE.LinearFilter;
            videoTexture.magFilter = THREE.LinearFilter;

            videoHeight = 1 / videoAspect;
            
            // GEOMETRY SETUP
            // 1. Create Plane (Default is XY plane, Normal +Z)
            const geometry = new THREE.PlaneGeometry(1, videoHeight);
            
            // 2. TRANSLATE (Offset): Move it UP by half height. 
            // This puts the bottom edge of the video at (0,0,0) - The Reticle center.
            geometry.translate(0, videoHeight / 2, 0);

            // 3. ROTATE: Align to Surface.
            // Reticle is rotated -90 X to lie flat. 
            // We rotate the video -90 X as well so it aligns with the Reticle/Surface.
            // Since we translated Y up (local), rotating X -90 makes that "Up" point along the surface (-Z).
            // This creates a "Flush" effect (Poster on Wall, Rug on Floor).
            geometry.rotateX(-Math.PI / 2);

            const material = new THREE.MeshBasicMaterial({ 
                map: videoTexture, 
                side: THREE.DoubleSide 
            });

            videoMesh = new THREE.Mesh(geometry, material);
            videoMesh.visible = false;
            scene.add(videoMesh);
        }

        function onSelect() {
            if (reticle.visible && !isVideoPlaced) {
                // PLACE VIDEO
                // Copy position and rotation exactly from Reticle
                // Because we pre-rotated the geometry, it will align flush.
                videoMesh.position.setFromMatrixPosition(reticle.matrix);
                videoMesh.quaternion.setFromRotationMatrix(reticle.matrix);
                
                videoMesh.visible = true;
                isVideoPlaced = true;
                videoElement.play();
                videoElement.muted = false; 
                feedbackEl.classList.remove('visible');
            } 
            else if (isVideoPlaced) {
                // INTERACT (Play/Pause)
                // Use Raycaster to check if we tapped the video
                tempMatrix.identity().extractRotation(controller.matrixWorld);
                raycaster.ray.origin.setFromMatrixPosition(controller.matrixWorld);
                raycaster.ray.direction.set(0, 0, -1).applyMatrix4(tempMatrix);

                const intersects = raycaster.intersectObject(videoMesh);

                if (intersects.length > 0) {
                    if (videoElement.paused) videoElement.play();
                    else videoElement.pause();
                }
            }
        }

        // --- IMPROVED PINCH LOGIC ---

        function onTouchStart(e) {
            // Check for 2 fingers
            if (e.touches.length === 2 && isVideoPlaced) {
                isPinching = true;
                // Calculate distance between fingers
                const dx = e.touches[0].clientX - e.touches[1].clientX;
                const dy = e.touches[0].clientY - e.touches[1].clientY;
                touchStartDistance = Math.hypot(dx, dy); // hypot is safer math
                
                // Save current scale
                startScale.copy(videoMesh.scale);
            }
        }

        function onTouchMove(e) {
            if (isPinching && e.touches.length === 2 && isVideoPlaced) {
                // PREVENT BROWSER ZOOM
                if (e.cancelable) e.preventDefault(); 
                e.stopPropagation();

                const dx = e.touches[0].clientX - e.touches[1].clientX;
                const dy = e.touches[0].clientY - e.touches[1].clientY;
                const currentDist = Math.hypot(dx, dy);

                if (touchStartDistance > 10) { // Threshold to avoid jitter
                    const scaleFactor = currentDist / touchStartDistance;
                    
                    // Apply scale with limits (0.2x to 6x)
                    const newScale = Math.max(0.2, Math.min(startScale.x * scaleFactor, 6.0));
                    videoMesh.scale.setScalar(newScale);
                }
            }
        }

        function onTouchEnd(e) {
            // If fingers dropped below 2, stop pinching
            if (e.touches.length < 2) {
                isPinching = false;
            }
        }

        // --- SYSTEM LOOP ---

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function animate() {
            renderer.setAnimationLoop(render);
        }

        function render(timestamp, frame) {
            if (frame) {
                const session = renderer.xr.getSession();
                if (!session) return;

                if (!hitTestSourceRequested) {
                    session.requestReferenceSpace('viewer').then((refSpace) => {
                        session.requestHitTestSource({ space: refSpace }).then((source) => {
                            hitTestSource = source;
                        }).catch((err) => {});
                    });
                    
                    session.addEventListener('end', () => {
                        hitTestSourceRequested = false;
                        hitTestSource = null;
                        setupPanel.style.display = 'block';
                        videoElement.pause();
                        videoMesh.visible = false;
                        isVideoPlaced = false;
                        feedbackEl.classList.remove('visible');
                    });
                    
                    hitTestSourceRequested = true;
                }

                if (hitTestSource && !isVideoPlaced) {
                    const hitTestResults = frame.getHitTestResults(hitTestSource);
                    if (hitTestResults.length > 0) {
                        const hit = hitTestResults[0];
                        const refSpace = renderer.xr.getReferenceSpace();
                        
                        reticle.visible = true;
                        reticle.matrix.fromArray(hit.getPose(refSpace).transform.matrix);
                        
                        // Detect if Wall or Floor based on Rotation
                        // Extract rotation from matrix
                        const rot = new THREE.Euler().setFromRotationMatrix(reticle.matrix);
                        // If X rotation is near -90 deg (approx -1.57), it's likely Floor/Ceiling
                        // If X rotation is near 0, it's likely Wall
                        
                        // Just nice feedback for user
                        feedbackEl.textContent = "Tap to Place";
                        feedbackEl.classList.add('visible');
                    } else {
                        reticle.visible = false;
                        feedbackEl.textContent = "Scan Wall or Floor...";
                        feedbackEl.classList.add('visible');
                    }
                } else if (isVideoPlaced) {
                    feedbackEl.classList.remove('visible');
                }
            }
            renderer.render(scene, camera);
        }
    </script>
</body>
</html>

